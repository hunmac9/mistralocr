# Dockerfile for Local OCR service with GPU support
# Supports: Surya OCR (~300M params) and PaddleOCR-VL (0.9B params)

FROM ubuntu:22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Install Python and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-venv \
    python3-pip \
    libmupdf-dev \
    mupdf-tools \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && ln -sf /usr/bin/python3.11 /usr/bin/python3 \
    && ln -sf /usr/bin/python3.11 /usr/bin/python

# Note: PyTorch with CUDA bundles the necessary CUDA runtime libraries
# The NVIDIA Container Toolkit on the host provides GPU access

WORKDIR /app

# Create non-root user
RUN addgroup --system appgroup && adduser --system --ingroup appgroup appuser

# Copy requirements
COPY requirements.txt .

# Install all dependencies first (filter out CPU torch references)
# This lets pip resolve the correct torch version for surya-ocr
# PyPI torch 2.9.x already includes CUDA support (bundles cu128 libraries)
RUN grep -v "torch" requirements.txt | grep -v "extra-index-url.*cpu" | pip install --no-cache-dir -r /dev/stdin

# Install matching torchvision from PyPI (torch from PyPI already has CUDA)
RUN pip install --no-cache-dir torchvision

# Install flash-attention for PaddleOCR-VL optimization (optional but recommended)
# Note: Requires ninja and packaging for build
RUN pip install --no-cache-dir ninja packaging && \
    pip install --no-cache-dir flash-attn --no-build-isolation || \
    echo "Flash-attention installation failed (optional), continuing without it"

# Verify CUDA torch is installed and show versions
RUN python -c "import torch; import torchvision; print(f'PyTorch {torch.__version__}'); print(f'TorchVision {torchvision.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"

# Copy application
COPY ocr_server.py .

# Setup directories and permissions
RUN mkdir -p /home/appuser/.cache && chown -R appuser:appgroup /home/appuser /app

USER appuser

# Environment
ENV PORT=8000
ENV HOST=0.0.0.0
ENV IDLE_TIMEOUT=300
ENV DEFAULT_MODEL=surya
ENV FORCE_CUDA=true
ENV HF_HOME=/home/appuser/.cache/huggingface
ENV TRANSFORMERS_CACHE=/home/appuser/.cache/huggingface

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=5 \
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')" || exit 1

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--timeout", "600", "--workers", "1", "ocr_server:app"]
