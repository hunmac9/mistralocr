# Docker Compose for GPU-enabled deployment
# Use with: docker compose -f docker-compose.gpu.yml up -d --build
#
# Requirements:
# - NVIDIA GPU with CUDA support
# - NVIDIA Container Toolkit installed

services:
  # Main application service
  app:
    build: .
    ports:
      - "${FLASK_PORT:-5009}:${FLASK_PORT:-5009}"
    environment:
      MISTRAL_API_KEY: ${MISTRAL_API_KEY:-}
      FLASK_PORT: ${FLASK_PORT:-5009}
      MAX_UPLOAD_MB: ${MAX_UPLOAD_MB:-100}
      MISTRAL_MAX_MB: ${MISTRAL_MAX_MB:-50}
      SERVER_NAME: ${SERVER_NAME:-localhost:${FLASK_PORT:-5009}}
      FLASK_DEBUG: ${FLASK_DEBUG:-False}
      OCR_BACKEND: ${OCR_BACKEND:-auto}
      LOCAL_OCR_URL: http://local-ocr:8000
      LOCAL_OCR_IDLE_TIMEOUT: ${LOCAL_OCR_IDLE_TIMEOUT:-300}
      LOCAL_OCR_AUTO_START: "false"
    depends_on:
      local-ocr:
        condition: service_healthy
    networks:
      - ocr-network
    command: ["gunicorn", "--bind", "0.0.0.0:${FLASK_PORT:-5009}", "--timeout", "600", "app:app"]

  # Local OCR server with GPU support - Surya OCR + PaddleOCR-VL
  local-ocr:
    build:
      context: ./local_ocr
      dockerfile: Dockerfile.gpu
    environment:
      IDLE_TIMEOUT: ${LOCAL_OCR_IDLE_TIMEOUT:-300}
      OCR_BACKEND: ${OCR_BACKEND:-surya}  # "surya" or "paddleocr-vl"
      FORCE_CUDA: "true"
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - ocr-cache:/home/appuser/.cache
    networks:
      - ocr-network
    # Required for GPU memory access
    ipc: host
    # GPU passthrough configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

networks:
  ocr-network:
    driver: bridge

volumes:
  ocr-cache:
